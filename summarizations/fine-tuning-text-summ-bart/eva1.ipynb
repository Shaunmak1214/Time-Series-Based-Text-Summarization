{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fastai.text.all import *\n",
    "from transformers import *\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.all import *\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation data\n",
    "validation_df = pd.read_csv('./sosum-data/processed_answer.csv')\n",
    "\n",
    "# Preprocess the validation data\n",
    "validation_df['content'] = validation_df['content'].apply(lambda x: x.replace('/', ''))\n",
    "validation_df['content'] = validation_df['content'].apply(lambda x: x.replace('\\xa0', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\blurr\\modeling\\seq2seq\\core.py:42: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  compute_func = hf_load_metric(metric_name).compute\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x21b871b5f50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, \n",
    "                                                                  model_cls=BartForConditionalGeneration)\n",
    "\n",
    "hf_batch_tfm = HF_Seq2SeqBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model, task='summarization',\n",
    "text_gen_kwargs={'max_length': 248,\n",
    " 'min_length': 56,\n",
    " 'do_sample': False,\n",
    " 'early_stopping': True,\n",
    " 'num_beams': 4,\n",
    " 'temperature': 1.0,\n",
    " 'top_k': 50,\n",
    " 'top_p': 1.0,\n",
    " 'repetition_penalty': 1.0,\n",
    " 'bad_words_ids': None,\n",
    " 'bos_token_id': 0,\n",
    " 'pad_token_id': 1,\n",
    " 'eos_token_id': 2,\n",
    " 'length_penalty': 2.0,\n",
    " 'no_repeat_ngram_size': 3,\n",
    " 'encoder_no_repeat_ngram_size': 0,\n",
    " 'num_return_sequences': 1,\n",
    " 'decoder_start_token_id': 2,\n",
    " 'use_cache': True,\n",
    " 'num_beam_groups': 1,\n",
    " 'diversity_penalty': 0.0,\n",
    " 'output_attentions': False,\n",
    " 'output_hidden_states': False,\n",
    " 'output_scores': False,\n",
    " 'return_dict_in_generate': False,\n",
    " 'forced_bos_token_id': 0,\n",
    " 'forced_eos_token_id': 2,\n",
    " 'remove_invalid_values': False})\n",
    "\n",
    "blocks = (HF_Seq2SeqBlock(before_batch_tfm=hf_batch_tfm), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader('content'), get_y=ColReader('title'), splitter=RandomSplitter())\n",
    "\n",
    "dls = dblock.dataloaders(validation_df, bs=2)\n",
    "\n",
    "seq2seq_metrics = {\n",
    "        'rouge': {\n",
    "            'compute_kwargs': { 'rouge_types': [\"rouge1\", \"rouge2\", \"rougeL\"], 'use_stemmer': True },\n",
    "            'returns': [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "        },\n",
    "        'bertscore': {\n",
    "            'compute_kwargs': { 'lang': 'fr' },\n",
    "            'returns': [\"precision\", \"recall\", \"f1\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "model = HF_BaseModelWrapper(hf_model)\n",
    "learn_cbs = [HF_BaseModelCallback]\n",
    "fit_cbs = [HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics),  Recorder()]\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=ranger,\n",
    "                loss_func=CrossEntropyLossFlat(),\n",
    "                cbs=learn_cbs,\n",
    "                splitter=partial(seq2seq_splitter, arch=hf_arch)).to_fp16()\n",
    "\n",
    "learn.load('lemonde_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:22<00:00,  8.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the validation data\n",
    "\n",
    "# slice the validation data to 1000 rows\n",
    "validation_df = validation_df[:10]\n",
    "\n",
    "preds = []\n",
    "for text in tqdm(validation_df['content']):\n",
    "    output = learn.blurr_generate(text, early_stopping=True, num_beams=4, max_length=248, min_length=56)\n",
    "    preds.append(output[0])\n",
    "\n",
    "# Get the true labels from the validation data\n",
    "true_labels = validation_df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'r': 0.2686868686868687, 'p': 0.1616443745082612, 'f': 0.1893924217805424}, 'rouge-2': {'r': 0.21252480038058788, 'p': 0.12679635258358662, 'f': 0.1485575561288716}, 'rouge-l': {'r': 0.2686868686868687, 'p': 0.1616443745082612, 'f': 0.1893924217805424}}\n"
     ]
    }
   ],
   "source": [
    "true_labels = validation_df['title'].to_list()\n",
    "# implement the rouge score\n",
    "from rouge import Rouge \n",
    "\n",
    "hyps, refs = preds, true_labels\n",
    "rouge = Rouge()\n",
    "\n",
    "scores = rouge.get_scores(hyps, refs, avg=True)\n",
    "\n",
    "# calculate the average rouge score\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write accuracy scores into a file\n",
    "with open('base_rouge_scores_ans.txt', 'w') as f:\n",
    "    f.write(str(scores))\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
