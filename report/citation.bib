@INPROCEEDINGS{stopwords_1,
  number={},
  author = {Gerlach, Martin and Shi, Hanyu and Amaral, Luís},
  year = {2019},
  month = {12},
  pages = {},
  title = {A universal information theoretic approach to the identification of stopwords},
  volume = {1},
  journal = {Nature Machine Intelligence},
  doi = {10.1038/s42256-019-0112-6}
}

@INPROCEEDINGS{stopwords_2,
  number={},
  author = {Sarica, Serhad and Luo, Jianxi},
  year = {2020},
  month = {06},
  pages = {},
  title = {Stopwords in Technical Language Processing},
  journal = {},
  doi = {}
}

@inproceedings{bugs_nightmare,
  title={Software Testing or The Bugs’ Nightmare},
  author={H{\'e}ctor D. Men{\'e}ndez},
  year={2021}
}

@INPROCEEDINGS{8816796,
  author={Manes, Saraj Singh and Baysal, Olga},
  booktitle={2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)}, 
  title={How Often and What StackOverflow Posts Do Developers Reference in Their GitHub Projects?}, 
  year={2019},
  volume={},
  number={},
  pages={235-239},
  doi={10.1109/MSR.2019.00047}
}

@INPROCEEDINGS{faq_gen_1,
  author = {Gupta, Sparsh and Carvalho, Vitor R.},
  title = {FAQ Retrieval Using Attentive Matching},
  year = {2019},
  isbn = {9781450361729},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3331184.3331294}, 
  doi = {10.1145/3331184.3331294},
  abstract = {The task of ranking question-answer pairs in response to an input query, aka FAQ (Frequently Asked Question) Retrieval, has traditionally been focused mostly on extracting relevance signals between query and questions based on extensive manual feature engineering. In this paper we propose multiple deep learning architectures designed for FAQ Retrieval that eliminate the need for feature engineering and are able to elegantly combine both query-question and query-answer similarities. We present experimental results showing that models that effectively combine both query-question and query-answer representations using attention mechanisms in a hierarchical manner yield the best results from all proposed models. We further verify the effectiveness of attention mechanisms for FAQ Retrieval by conducting experiments on a completely different attention-based architecture, originally designed for question duplicate detection tasks, and observing equally impressive experimental ranking results.},
  booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages = {929–932},
  numpages = {4},
  keywords = {attention mechanism, learning to rank, neural networks},
  location = {Paris, France},
  series = {SIGIR'19}
}


@inproceedings{10.1007/978-3-319-42911-3_25,
	abstract = {We propose an FAQ (Frequently Asked Question) search method that uses classification results of input queries. FAQs aim at covering frequently asked topics and users usually search topics in FAQs with queries represented by bag-of-words or natural language sentences. However, there is a problem that each question in FAQs is not usually sufficient enough to cover variety of queries that have the similar meaning but different surface expressions, such as synonyms, paraphrase and causal relations due to each topic usually consists of a representative question and its answer. As a result, users who cannot find their answers in FAQs ask a call center operator. To consider similarity of meaning among different surface expressions, we use a document classifier that classifies each query into topics of FAQs. A document classifier is trained with not only FAQs but also corresponding histories of operators for covering variety of queries. However, corresponding histories do not include links to FAQs, we use a method for generating training data from the corresponding histories with FAQs. To generate training data correctly, the method takes advantage of a characteristic that many answers in corresponding histories related to FAQs are created by quoting corresponding FAQs. Our method uses a surface similarity between answers in corresponding histories and the answer part of each topic in FAQs for automatically generating training data. Experimental results show that our method outperforms an FAQ search based method using word matching in terms of Mean Reciprocal Rank and Precision@N.},
	address = {Cham},
	author = {Makino, Takuya and Noro, Tomoya and Iwakura, Tomoya},
	booktitle = {PRICAI 2016: Trends in Artificial Intelligence},
	editor = {Booth, Richard and Zhang, Min-Ling},
	isbn = {978-3-319-42911-3},
	pages = {295--305},
	publisher = {Springer International Publishing},
	title = {An FAQ Search Method Using a Document Classifier Trained with Automatically Generated Training Data},
	year = {2016}
  }


@inproceedings{10.1007/978-3-319-18356-5_30,
	abstract = {Using Frequently Asked Questions (FAQs) is a popular way of documenting the list of common questions on particular topics or specific contexts. Most FAQ pages on the Internet are static and can quickly become outdated. We propose to extend the existing work on question answering systems to generating FAQ lists. In conventional Question Answering (QA) systems, users are only allowed to express their queries in a natural language format. A new methodology is proposed to construct the questions by combining of question extraction and question generation methods. The proposed system accepts, extracts, or generates user questions in order to create, maintain, and improve the FAQs quality. In addition to present the basis of QA system, complimentary units will be added to conduct the FAQ list. The research proposed here will contribute to the field of Natural Language Processing, Text Mining, QA, particularly to provide high quality automatic FAQ generation and retrieval.},
	address = {Cham},
	author = {Raazaghi, Fatemeh},
	booktitle = {Advances in Artificial Intelligence},
	editor = {Barbosa, Denilson and Milios, Evangelos},
	isbn = {978-3-319-18356-5},
	pages = {334--337},
	publisher = {Springer International Publishing},
	title = {Auto-FAQ-Gen: Automatic Frequently Asked Questions Generation},
	year = {2015}}


@INPROCEEDINGS{5615722,
  author={Hu, Wei-Chung and Yu, Dung-Feng and Jiau, Hewijin Christine},
  booktitle={2010 Fifth International Conference on Software Engineering Advances}, 
  title={A FAQ Finding Process in Open Source Project Forums}, 
  year={2010},
  volume={},
  number={},
  pages={259-264},
  doi={10.1109/ICSEA.2010.46}}

@INPROCEEDINGS{6227139,
  author={Henß, Stefan and Monperrus, Martin and Mezini, Mira},
  booktitle={2012 34th International Conference on Software Engineering (ICSE)}, 
  title={Semi-automatically extracting FAQs to improve accessibility of software development knowledge}, 
  year={2012},
  volume={},
  number={},
  pages={793-803},
  doi={10.1109/ICSE.2012.6227139}}

@INPROCEEDINGS{7817112,
  author={Razzaghi, Fatemeh and Minaee, Hamed and Ghorbani, Ali A.},
  booktitle={2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)}, 
  title={Context Free Frequently Asked Questions Detection Using Machine Learning Techniques}, 
  year={2016},
  volume={},
  number={},
  pages={558-561},
  doi={10.1109/WI.2016.0095}}

@inproceedings{sms_faq_retrieval,
author = {Kothari, Govind and Negi, Sumit and Faruquie, Tanveer and Chakaravarthy, Venkatesan and Subramaniam, L.V.},
year = {2009},
month = {01},
pages = {852-860},
title = {SMS based interface for FAQ retrieval},
doi = {10.3115/1690219.1690266}
}

@article{Improving_question_retrieval_in_community_question_answering_using_world_knowledge,
author = {Zhou, Guangyou and Liu, Y. and Liu, F. and Zeng, D. and Zhao, J.},
year = {2013},
month = {01},
pages = {2239-2245},
title = {Improving question retrieval in community question answering using world knowledge},
journal = {IJCAI International Joint Conference on Artificial Intelligence}
}

@INPROCEEDINGS{8054419,
  author={Zhang, Shengnan and Hu, Yan and Bian, Guangrong},
  booktitle={2017 IEEE 2nd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)}, 
  title={Research on string similarity algorithm based on Levenshtein Distance}, 
  year={2017},
  volume={},
  number={},
  pages={2247-2251},
  doi={10.1109/IAEAC.2017.8054419}}


@article{OTHMAN2019485,
	abstract = {Community Question Answering (CQA) services have evolved into a popular way of online information seeking, where users can interact and exchange knowledge in the form of questions and answers. In this paper, we study the problem of finding historical questions that are semantically equivalent to the queried ones, assuming that the answers to the similar questions should also answer the new ones. The major challenge of question retrieval is the word mismatch problem between questions, as users can formulate the same question using different wording. Most existing methods measure the similarity between questions based on the bag-of-words (BOWs) representation capturing no semantics between words. Therefore, this study proposes to use word embeddings, which can capture semantic and syntactic information from contexts, to vectorize the questions. The questions are clustered using Kmeans to speed up the search and ranking tasks. The similarity between the questions is measured using cosine similarity based on their weighted continuous valued vectors. We run our experiments on real world data set from Yahoo! Answers in English and Arabic to show the efficiency and generality of our proposed method.},
	author = {Nouha Othman and Rim Faiz and Kamel Sma{\"\i}li},
	doi = {https://doi.org/10.1016/j.procs.2019.09.203},
	issn = {1877-0509},
	journal = {Procedia Computer Science},
	keywords = {Community Question Answering, Question retrieval, Word embeddings},
	note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
	pages = {485-494},
	title = {Enhancing Question Retrieval in Community Question Answering Using Word Embeddings},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050919313857},
	volume = {159},
	year = {2019},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1877050919313857},
	bdsk-url-2 = {https://doi.org/10.1016/j.procs.2019.09.203}
}