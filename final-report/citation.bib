@INPROCEEDINGS{stopwords_1,
  number={},
  author = {Gerlach, Martin and Shi, Hanyu and Amaral, Luís},
  year = {2019},
  month = {12},
  pages = {},
  title = {A universal information theoretic approach to the identification of stopwords},
  volume = {1},
  journal = {Nature Machine Intelligence},
  doi = {10.1038/s42256-019-0112-6}
}

@INPROCEEDINGS{stopwords_2,
  number={},
  author = {Sarica, Serhad and Luo, Jianxi},
  year = {2020},
  month = {06},
  pages = {},
  title = {Stopwords in Technical Language Processing},
  journal = {},
  doi = {}
}

@INPROCEEDINGS{9074166,
  author={Ladani, Dhara J. and Desai, Nikita P.},
  booktitle={2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)}, 
  title={Stopword Identification and Removal Techniques on TC and IR applications: A Survey}, 
  year={2020},
  volume={},
  number={},
  pages={466-472},
  doi={10.1109/ICACCS48705.2020.9074166}}


@inproceedings{NIPS2013_9aa42b31,
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger},
	publisher = {Curran Associates, Inc.},
	title = {Distributed Representations of Words and Phrases and their Compositionality},
	url = {https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf},
	volume = {26},
	year = {2013},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf}}


@inproceedings{bugs_nightmare,
  title={Software Testing or The Bugs’ Nightmare},
  author={H{\'e}ctor D. Men{\'e}ndez},
  year={2021}
}

@INPROCEEDINGS{8816796,
  author={Manes, Saraj Singh and Baysal, Olga},
  booktitle={2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)}, 
  title={How Often and What StackOverflow Posts Do Developers Reference in Their GitHub Projects?}, 
  year={2019},
  volume={},
  number={},
  pages={235-239},
  doi={10.1109/MSR.2019.00047}
}

@INPROCEEDINGS{faq_gen_1,
  author = {Gupta, Sparsh and Carvalho, Vitor R.},
  title = {FAQ Retrieval Using Attentive Matching},
  year = {2019},
  isbn = {9781450361729},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3331184.3331294}, 
  doi = {10.1145/3331184.3331294},
  abstract = {The task of ranking question-answer pairs in response to an input query, aka FAQ (Frequently Asked Question) Retrieval, has traditionally been focused mostly on extracting relevance signals between query and questions based on extensive manual feature engineering. In this paper we propose multiple deep learning architectures designed for FAQ Retrieval that eliminate the need for feature engineering and are able to elegantly combine both query-question and query-answer similarities. We present experimental results showing that models that effectively combine both query-question and query-answer representations using attention mechanisms in a hierarchical manner yield the best results from all proposed models. We further verify the effectiveness of attention mechanisms for FAQ Retrieval by conducting experiments on a completely different attention-based architecture, originally designed for question duplicate detection tasks, and observing equally impressive experimental ranking results.},
  booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages = {929–932},
  numpages = {4},
  keywords = {attention mechanism, learning to rank, neural networks},
  location = {Paris, France},
  series = {SIGIR'19}
}


@inproceedings{10.1007/978-3-319-42911-3_25,
	abstract = {We propose an FAQ (Frequently Asked Question) search method that uses classification results of input queries. FAQs aim at covering frequently asked topics and users usually search topics in FAQs with queries represented by bag-of-words or natural language sentences. However, there is a problem that each question in FAQs is not usually sufficient enough to cover variety of queries that have the similar meaning but different surface expressions, such as synonyms, paraphrase and causal relations due to each topic usually consists of a representative question and its answer. As a result, users who cannot find their answers in FAQs ask a call center operator. To consider similarity of meaning among different surface expressions, we use a document classifier that classifies each query into topics of FAQs. A document classifier is trained with not only FAQs but also corresponding histories of operators for covering variety of queries. However, corresponding histories do not include links to FAQs, we use a method for generating training data from the corresponding histories with FAQs. To generate training data correctly, the method takes advantage of a characteristic that many answers in corresponding histories related to FAQs are created by quoting corresponding FAQs. Our method uses a surface similarity between answers in corresponding histories and the answer part of each topic in FAQs for automatically generating training data. Experimental results show that our method outperforms an FAQ search based method using word matching in terms of Mean Reciprocal Rank and Precision@N.},
	address = {Cham},
	author = {Makino, Takuya and Noro, Tomoya and Iwakura, Tomoya},
	booktitle = {PRICAI 2016: Trends in Artificial Intelligence},
	editor = {Booth, Richard and Zhang, Min-Ling},
	isbn = {978-3-319-42911-3},
	pages = {295--305},
	publisher = {Springer International Publishing},
	title = {An FAQ Search Method Using a Document Classifier Trained with Automatically Generated Training Data},
	year = {2016}
  }


@inproceedings{10.1007/978-3-319-18356-5_30,
	abstract = {Using Frequently Asked Questions (FAQs) is a popular way of documenting the list of common questions on particular topics or specific contexts. Most FAQ pages on the Internet are static and can quickly become outdated. We propose to extend the existing work on question answering systems to generating FAQ lists. In conventional Question Answering (QA) systems, users are only allowed to express their queries in a natural language format. A new methodology is proposed to construct the questions by combining of question extraction and question generation methods. The proposed system accepts, extracts, or generates user questions in order to create, maintain, and improve the FAQs quality. In addition to present the basis of QA system, complimentary units will be added to conduct the FAQ list. The research proposed here will contribute to the field of Natural Language Processing, Text Mining, QA, particularly to provide high quality automatic FAQ generation and retrieval.},
	address = {Cham},
	author = {Raazaghi, Fatemeh},
	booktitle = {Advances in Artificial Intelligence},
	editor = {Barbosa, Denilson and Milios, Evangelos},
	isbn = {978-3-319-18356-5},
	pages = {334--337},
	publisher = {Springer International Publishing},
	title = {Auto-FAQ-Gen: Automatic Frequently Asked Questions Generation},
	year = {2015}}


@INPROCEEDINGS{5615722,
  author={Hu, Wei-Chung and Yu, Dung-Feng and Jiau, Hewijin Christine},
  booktitle={2010 Fifth International Conference on Software Engineering Advances}, 
  title={A FAQ Finding Process in Open Source Project Forums}, 
  year={2010},
  volume={},
  number={},
  pages={259-264},
  doi={10.1109/ICSEA.2010.46}}

@INPROCEEDINGS{6227139,
  author={Henß, Stefan and Monperrus, Martin and Mezini, Mira},
  booktitle={2012 34th International Conference on Software Engineering (ICSE)}, 
  title={Semi-automatically extracting FAQs to improve accessibility of software development knowledge}, 
  year={2012},
  volume={},
  number={},
  pages={793-803},
  doi={10.1109/ICSE.2012.6227139}}

@INPROCEEDINGS{7817112,
  author={Razzaghi, Fatemeh and Minaee, Hamed and Ghorbani, Ali A.},
  booktitle={2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)}, 
  title={Context Free Frequently Asked Questions Detection Using Machine Learning Techniques}, 
  year={2016},
  volume={},
  number={},
  pages={558-561},
  doi={10.1109/WI.2016.0095}}

@inproceedings{sms_faq_retrieval,
author = {Kothari, Govind and Negi, Sumit and Faruquie, Tanveer and Chakaravarthy, Venkatesan and Subramaniam, L.V.},
year = {2009},
month = {01},
pages = {852-860},
title = {SMS based interface for FAQ retrieval},
doi = {10.3115/1690219.1690266}
}

@article{Improving_question_retrieval_in_community_question_answering_using_world_knowledge,
author = {Zhou, Guangyou and Liu, Y. and Liu, F. and Zeng, D. and Zhao, J.},
year = {2013},
month = {01},
pages = {2239-2245},
title = {Improving question retrieval in community question answering using world knowledge},
journal = {IJCAI International Joint Conference on Artificial Intelligence}
}

@INPROCEEDINGS{8054419,
  author={Zhang, Shengnan and Hu, Yan and Bian, Guangrong},
  booktitle={2017 IEEE 2nd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)}, 
  title={Research on string similarity algorithm based on Levenshtein Distance}, 
  year={2017},
  volume={},
  number={},
  pages={2247-2251},
  doi={10.1109/IAEAC.2017.8054419}}


@article{OTHMAN2019485,
	abstract = {Community Question Answering (CQA) services have evolved into a popular way of online information seeking, where users can interact and exchange knowledge in the form of questions and answers. In this paper, we study the problem of finding historical questions that are semantically equivalent to the queried ones, assuming that the answers to the similar questions should also answer the new ones. The major challenge of question retrieval is the word mismatch problem between questions, as users can formulate the same question using different wording. Most existing methods measure the similarity between questions based on the bag-of-words (BOWs) representation capturing no semantics between words. Therefore, this study proposes to use word embeddings, which can capture semantic and syntactic information from contexts, to vectorize the questions. The questions are clustered using Kmeans to speed up the search and ranking tasks. The similarity between the questions is measured using cosine similarity based on their weighted continuous valued vectors. We run our experiments on real world data set from Yahoo! Answers in English and Arabic to show the efficiency and generality of our proposed method.},
	author = {Nouha Othman and Rim Faiz and Kamel Sma{\"\i}li},
	doi = {https://doi.org/10.1016/j.procs.2019.09.203},
	issn = {1877-0509},
	journal = {Procedia Computer Science},
	keywords = {Community Question Answering, Question retrieval, Word embeddings},
	note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
	pages = {485-494},
	title = {Enhancing Question Retrieval in Community Question Answering Using Word Embeddings},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050919313857},
	volume = {159},
	year = {2019},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1877050919313857},
	bdsk-url-2 = {https://doi.org/10.1016/j.procs.2019.09.203}
}

@inproceedings{duan-etal-2017-question,
    title = "Question Generation for Question Answering",
    author = "Duan, Nan  and
      Tang, Duyu  and
      Chen, Peng  and
      Zhou, Ming",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1090",
    doi = "10.18653/v1/D17-1090",
    pages = "866--874",
    abstract = "This paper presents how to generate questions from given passages using neural networks, where large scale QA pairs are automatically crawled and processed from Community-QA website, and used as training data. The contribution of the paper is 2-fold: First, two types of question generation approaches are proposed, one is a retrieval-based method using convolution neural network (CNN), the other is a generation-based method using recurrent neural network (RNN); Second, we show how to leverage the generated questions to improve existing question answering systems. We evaluate our question generation method for the answer sentence selection task on three benchmark datasets, including SQuAD, MS MARCO, and WikiQA. Experimental results show that, by using generated questions as an extra signal, significant QA improvement can be achieved.",
}

@INPROCEEDINGS{9144082,
  author={WANJAWA, Barack and MUCHEMI, Lawrence},
  booktitle={2020 IST-Africa Conference (IST-Africa)}, 
  title={Question Answering using Automatically Generated Semantic Networks – the case of Swahili Questions}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  doi={}}

@inproceedings{10.1145/1099554.1099571,
author = {Jijkoun, Valentin and de Rijke, Maarten},
title = {Retrieving Answers from Frequently Asked Questions Pages on the Web},
year = {2005},
isbn = {1595931406},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1099554.1099571},
doi = {10.1145/1099554.1099571},
abstract = {We address the task of answering natural language questions by using the large number of Frequently Asked Questions (FAQ) pages available on the web. The task involves three steps: (1) fetching FAQ pages from the web; (2) automatic extraction of question/answer (Q/A) pairs from the collected pages; and (3) answering users' questions by retrieving appropriate Q/A pairs. We discuss our solutions for each of the three tasks, and give detailed evaluation results on a collected corpus of about 3.6Gb of text data (293K pages, 2.8M Q/A pairs), with real users' questions sampled from a web search engine log. Specifically, we propose simple but effective methods for Q/A extraction and investigate task-specific retrieval models for answering questions. Our best model finds answers for 36\% of the test questions in the top 20 results. Our overall conclusion is that FAQ pages on the web provide an excellent resource for addressing real users' information needs in a highly focused manner.},
booktitle = {Proceedings of the 14th ACM International Conference on Information and Knowledge Management},
pages = {76–83},
numpages = {8},
keywords = {questions beyond factoids, question answering, FAQ retrieval},
location = {Bremen, Germany},
series = {CIKM '05}
}

@INPROCEEDINGS{6227139,
  author={Henß, Stefan and Monperrus, Martin and Mezini, Mira},
  booktitle={2012 34th International Conference on Software Engineering (ICSE)}, 
  title={Semi-automatically extracting FAQs to improve accessibility of software development knowledge}, 
  year={2012},
  volume={},
  number={},
  pages={793-803},
  doi={10.1109/ICSE.2012.6227139}}


@article{ABSAUSGRD2019,
author = {Alqaryouti, Omar and Siyam, Nur and Monem, Azza and Shaalan, Khaled},
year = {2019},
month = {11},
pages = {},
title = {Aspect-Based Sentiment Analysis Using Smart Government Review Data},
volume = {ahead-of-print},
journal = {Applied Computing and Informatics},
doi = {10.1016/j.aci.2019.11.003}
}

@ARTICLE{9260162,
  author={Liu, Haoyue and Chatterjee, Ishani and Zhou, MengChu and Lu, Xiaoyu Sean and Abusorrah, Abdullah},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Aspect-Based Sentiment Analysis: A Survey of Deep Learning Methods}, 
  year={2020},
  volume={7},
  number={6},
  pages={1358-1375},
  doi={10.1109/TCSS.2020.3033302}}

@inproceedings{xue-li-2018-aspect,
    title = "Aspect Based Sentiment Analysis with Gated Convolutional Networks",
    author = "Xue, Wei  and
      Li, Tao",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1234",
    doi = "10.18653/v1/P18-1234",
    pages = "2514--2523",
    abstract = "Aspect based sentiment analysis (ABSA) can provide more detailed information than general sentiment analysis, because it aims to predict the sentiment polarities of the given aspects or entities in text. We summarize previous approaches into two subtasks: aspect-category sentiment analysis (ACSA) and aspect-term sentiment analysis (ATSA). Most previous approaches employ long short-term memory and attention mechanisms to predict the sentiment polarity of the concerned targets, which are often complicated and need more training time. We propose a model based on convolutional neural networks and gating mechanisms, which is more accurate and efficient. First, the novel Gated Tanh-ReLU Units can selectively output the sentiment features according to the given aspect or entity. The architecture is much simpler than attention layer used in the existing models. Second, the computations of our model could be easily parallelized during training, because convolutional layers do not have time dependency as in LSTM layers, and gating units also work independently. The experiments on SemEval datasets demonstrate the efficiency and effectiveness of our models.",
}


@article{MABDELGWAD20226652,
	abstract = {Aspect-based Sentiment analysis (ABSA) accomplishes a fine-grained analysis that defines the aspects of a given document or sentence and the sentiments conveyed regarding each aspect. This level of analysis is the most detailed version that is capable of exploring the nuanced viewpoints of the reviews. The bulk of study in ABSA focuses on English with very little work available in Arabic. Most previous work in Arabic has been based on regular methods of machine learning that mainly depends on a group of rare resources and tools for analyzing and processing Arabic content such as lexicons, but the lack of those resources presents another challenge. In order to address these challenges, Deep Learning (DL)-based methods are proposed using two models based on Gated Recurrent Units (GRU) neural networks for ABSA. The first is a DL model that takes advantage of word and character representations by combining bidirectional GRU, Convolutional Neural Network (CNN), and Conditional Random Field (CRF) making up the (BGRU-CNN-CRF) model to extract the main opinionated aspects (OTE). The second is an interactive attention network based on bidirectional GRU (IAN-BGRU) to identify sentiment polarity toward extracted aspects. We evaluated our models using the benchmarked Arabic hotel reviews dataset. The results indicate that the proposed methods are better than baseline research on both tasks having 39.7% enhancement in F1-score for opinion target extraction (T2) and 7.58% in accuracy for aspect-based sentiment polarity classification (T3). Achieving F1 score of 70.67% for T2, and accuracy of 83.98% for T3.},
	author = {Mohammed M.Abdelgwad and Taysir Hassan {A Soliman} and Ahmed I.Taloba and Mohamed Fawzy Farghaly},
	doi = {https://doi.org/10.1016/j.jksuci.2021.08.030},
	issn = {1319-1578},
	journal = {Journal of King Saud University - Computer and Information Sciences},
	keywords = {Aspect-based sentiment analysis (ABSA), Deep learning, Opinion target extraction (OTE), Aspect sentiment polarity classification, BGRU-CNN-CRF and IAN-BGRU},
	number = {9},
	pages = {6652-6662},
	title = {Arabic aspect based sentiment analysis using bidirectional GRU based models},
	url = {https://www.sciencedirect.com/science/article/pii/S1319157821002482},
	volume = {34},
	year = {2022},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1319157821002482},
	bdsk-url-2 = {https://doi.org/10.1016/j.jksuci.2021.08.030}}


@article{SOABSAUMLT2021,
	abstract = {Web 2.0 facilitates the expression of views through diverse Internet applications which serve as a rich source of information. The textual expressions have latent information that when processed and analysed reveal the sentiment of the user/people. This is known as sentiment analysis, which is the process of computationally extracting the opinions and viewpoints from textual data and it is also known as opinion mining, review mining or attitude mining, etc. Aspect-level sentiment analysis is one among the three main types of sentiment analysis, where granule level processing takes place in which the different aspects of entities are harnessed to identify the sentiment orientations. The emergence of machine learning and deep learning techniques has made a striking mark towards aspect-oriented sentiment analysis. This paper presents a survey and review of different works from the recent literature on aspect-based sentiment analysis done using machine learning techniques.},
	author = {Syam Mohan E,R. Sunitha},
	eissn = {2515-8260},
	eprint = {https://ejmcm.com/article__fc9dd6d90bfe72a036f8a9ea0ede617e6773.pdf},
	issn = {2515-8260},
	journal = {European Journal of Molecular &amp; Clinical Medicine},
	keywords = {sentiment analysis,Aspect Based Sentiment Analysis,machine learning,Deep learning},
	number = {10},
	pages = {1664-1684},
	title = {Survey On Aspect Based Sentiment Analysis Using Machine Learning Techniques},
	url = {https://ejmcm.com/article_6773.html},
	volume = {7},
	year = {2021},
	bdsk-url-1 = {https://ejmcm.com/article_6773.html}}

@article{Zainuddin2018HybridSC,
  title={Hybrid sentiment classification on twitter aspect-based sentiment analysis},
  author={Nurulhuda Zainuddin and Ali Selamat and Roliana Ibrahim},
  journal={Applied Intelligence},
  year={2018},
  volume={48},
  pages={1218-1232}
}

@article{ABSAUDNASO2020,
author = {Kumar, Ravindra and Pannu, Husanbir and Malhi, Avleen},
year = {2020},
month = {04},
pages = {},
title = {Aspect-based sentiment analysis using deep networks and stochastic optimization},
volume = {32},
journal = {Neural Computing and Applications},
doi = {10.1007/s00521-019-04105-z}
}

@inproceedings{he-etal-2018-exploiting,
    title = "Exploiting Document Knowledge for Aspect-level Sentiment Classification",
    author = "He, Ruidan  and
      Lee, Wee Sun  and
      Ng, Hwee Tou  and
      Dahlmeier, Daniel",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-2092",
    doi = "10.18653/v1/P18-2092",
    pages = "579--585",
    abstract = "Attention-based long short-term memory (LSTM) networks have proven to be useful in aspect-level sentiment classification. However, due to the difficulties in annotating aspect-level data, existing public datasets for this task are all relatively small, which largely limits the effectiveness of those neural models. In this paper, we explore two approaches that transfer knowledge from document-level data, which is much less expensive to obtain, to improve the performance of aspect-level sentiment classification. We demonstrate the effectiveness of our approaches on 4 public datasets from SemEval 2014, 2015, and 2016, and we show that attention-based LSTM benefits from document-level knowledge in multiple ways.",
}

@article{AlSmadi2017DeepRN,
  title={Deep Recurrent neural network vs. support vector machine for aspect-based sentiment analysis of Arabic hotels' reviews},
  author={Mohammad Al-Smadi and Omar Qawasmeh and Mahmoud Al-Ayyoub and Yaser Jararweh and Brij Bhooshan Gupta},
  journal={J. Comput. Sci.},
  year={2017},
  volume={27},
  pages={386-393}
}

@article{Rezaeinia2019SentimentAB,
  title={Sentiment analysis based on improved pre-trained word embeddings},
  author={Seyed Mahdi Rezaeinia and Rouhollah Rahmani and Ali Ghodsi and Hadi Veisi},
  journal={Expert Syst. Appl.},
  year={2019},
  volume={117},
  pages={139-147}
}

@article{10.1016/j.neucom.2019.04.038,
author = {Zhang, Bowen and Xu, Xiaofei and Li, Xutao and Chen, Xiaojun and Ye, Yunming and Wang, Zhongjie},
title = {Sentiment Analysis through Critic Learning for Optimizing Convolutional Neural Networks with Rules},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {356},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.04.038},
doi = {10.1016/j.neucom.2019.04.038},
journal = {Neurocomput.},
month = {sep},
pages = {21–30},
numpages = {10},
keywords = {Sentiment analysis, Critic learning, First-order rules}
}

@article{10.1016/j.future.2018.10.041,
author = {Ma, Xiao and Zeng, Jiangfeng and Peng, Limei and Fortino, Giancarlo and Zhang, Yin},
title = {Modeling Multi-Aspects within One Opinionated Sentence Simultaneously for Aspect-Level Sentiment Analysis},
year = {2019},
issue_date = {Apr 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {93},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2018.10.041},
doi = {10.1016/j.future.2018.10.041},
journal = {Future Gener. Comput. Syst.},
month = {apr},
pages = {304–311},
numpages = {8},
keywords = {Position attention, Sentiment analysis, Aspect-level, Multi-aspects}
}

@article{Sindhu2019AspectBasedOM,
  title={Aspect-Based Opinion Mining on Student’s Feedback for Faculty Teaching Performance Evaluation},
  author={Irum Sindhu and Sher Muhammad Daudpota and Kamal Badar and Maheen Bakhtyar and Junaid Baber and Mohammad Nurunnabi},
  journal={IEEE Access},
  year={2019},
  volume={7},
  pages={108729-108741}
}

@INPROCEEDINGS{8449647,
  author={Moreno, Laura and Marcus, Andrian},
  booktitle={2018 IEEE/ACM 40th International Conference on Software Engineering: Companion (ICSE-Companion)}, 
  title={Automatic Software Summarization: The State of the Art}, 
  year={2018},
  volume={},
  number={},
  pages={530-531},
  doi={}}


@article{ATSMACR2022,
	abstract = {Text summarization is the process of condensing a long text into a shorter version by maintaining the key information and its meaning. Automatic text summarization can save time and helps in selecting the important and relevant sentences from the document. In extractive summarization techniques, sentences are picked up directly from the source document, whereas in abstractive summarization techniques, new sentences and phrases are generated from original source document. Majority of research is focused on extractive techniques, in the recent years, most of the research is inclined towards abstractive \& hybrid text summarization methods. This paper presents comprehensive survey on various works performed for automatic text summarization methods. Detailed study is done on the Extractive \& Abstractive techniques \& their comparison on different aspects. The paper also discusses the research gaps \& challenges that can motivate \& help researchers to identify the potential areas for research in this field.},
	author = {Sharma, Grishma and Sharma, Deepak},
	date = {2022/10/28},
	date-added = {2023-02-07 03:09:40 +0800},
	date-modified = {2023-02-07 03:09:40 +0800},
	doi = {10.1007/s42979-022-01446-w},
	id = {Sharma2022},
	isbn = {2661-8907},
	journal = {SN Computer Science},
	number = {1},
	pages = {33},
	title = {Automatic Text Summarization Methods: A Comprehensive Review},
	url = {https://doi.org/10.1007/s42979-022-01446-w},
	volume = {4},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1007/s42979-022-01446-w}}

@inproceedings{ATSUSTSRAB2016,
author = {Nallapati, Ramesh and Zhou, Bowen and Dos Santos, Cicero and Gulcehre, Caglar and Xiang, Bing},
year = {2016},
month = {02},
pages = {280-290},
title = {Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond},
doi = {10.18653/v1/K16-1028}
}

@article{ACNATTS2009,
author = {Antiqueira, Lucas and Oliveira, Osvaldo and da F. Costa, Luciano and Nunes, Maria},
year = {2009},
month = {02},
pages = {584-599},
title = {A complex network approach to text summarization},
volume = {179},
journal = {Information Sciences},
doi = {10.1016/j.ins.2008.10.032}
}

@article{ATSULSA2011,
author = {Mashechkin, Igor and Petrovskiy, Mikhail and Popov, D. and Tsarev, Dmitry},
year = {2011},
month = {11},
pages = {299-305},
title = {Automatic Text Summarization Using Latent Semantic Analysis},
volume = {37},
journal = {Programming and Computer Software},
doi = {10.1134/S0361768811060041}
}

@inproceedings{banarescu-etal-2013-abstract,
    title = "{A}bstract {M}eaning {R}epresentation for Sembanking",
    author = "Banarescu, Laura  and
      Bonial, Claire  and
      Cai, Shu  and
      Georgescu, Madalina  and
      Griffitt, Kira  and
      Hermjakob, Ulf  and
      Knight, Kevin  and
      Koehn, Philipp  and
      Palmer, Martha  and
      Schneider, Nathan",
    booktitle = "Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse",
    month = aug,
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W13-2322",
    pages = "178--186",
}